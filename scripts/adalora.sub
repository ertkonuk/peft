#!/bin/bash
#SBATCH -A llmservice_modelalignment_ptune
#SBATCH -p batch_block2 # luna / backfill / interactive
#SBATCH -N 1                   # number of nodes
#SBATCH -t 4:00:00              # wall time  (4 for luna, 8 for backfill, 2 for interactive)
#SBATCH -J llmservice_modelalignment_ptune:peft.lora.llama-2-7b-hf-boolq  # job name (<< CHANGE ! >>)
#SBATCH --ntasks-per-node=8     # n tasks per machine (one task per gpu) <required>
#SBATCH  --mail-type=BEGIN,END,FAIL

source containers.sh
export HYDRA_FULL_ERROR=1

# training params
model_name=$1
task=$2
gbs=128
mbs=1
max_steps=2000
val_check=100
save_steps=500
max_seq_length=2048

# force crashing on nccl issues like hanging broadcast
export NCCL_ASYNC_ERROR_HANDLING=1

proj_name="${scheme}_lora"
exp_name=`echo $SLURM_JOB_NAME | cut -d':' -f2-`
DATE=$(date "+%Y-%m-%d_%H-%M-%S")
DOCKER_EXP_DIR="/experiments/${proj_name}/${exp_name}/${DATE}"
EXP_DIR="$PROJHOME/${DOCKER_EXP_DIR}"
echo $proj_name $exp_name $EXP_DIR
mkdir -p $EXP_DIR

GPUS_PER_NODE=${SLURM_NTASKS_PER_NODE}
NNODES=${SLURM_JOB_NUM_NODES}
NUM_PROCESSES=$(expr $NNODES \* $GPUS_PER_NODE)

grad_accum_steps=$(expr $gbs \/ $mbs) $(expr $gbs \/ $(expr $mbs \* $NUM_PROCESSES))

# so processes know who to talk to
MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
MASTER_PORT=6000
export LAUNCHER="accelerate launch \
    --config_file configs/fsdp_config.yaml \
    --main_process_ip $MASTER_ADDR \
    --main_process_port $MASTER_PORT \
    --machine_rank \$SLURM_PROCID \
    --num_processes $NUM_PROCESSES \
    --num_machines $NNODES \
    "

read -r -d '' cmd <<EOF
echo "*******STARTING********" \
&& pip install -r /requirements/requirements.txt \
&& huggingface-cli login --token ${HF_TOKEN} \ 
&& export WANDB_API_KEY=${WANDB} \
&& cd /code \
&& echo "Starting training" \
&& ${LAUNCHER} \ 
--model_name=${model_name} \
--train_ds="/datasets/${task}/train.jsonl" \
--validation_ds="/datasets/${task}/validation.jsonl" \
--cache_dir=/hub \
--max_seq_len=${max_seq_len} \
--max_steps=${max_steps} \
--logging_steps=25 \
--eval_steps=${val_check} \
--save_steps=${save_steps} \
--bf16=True \
--packing=True \
--output_dir=${DOCKER_EXP_DIR}/training \
--per_device_train_batch_size {mbs} \
--gradient_accumulation_steps ${grad_accum_steps} \
--use_peft_adalora True \
--adalora_init_r 12 \
--adalora_target_r 4 \
--adalora_beta1 0.85 \
--adalora_beta2 0.85 \
--adalora_tinit 200 \
--adalora_tfinal 1000 \
--adalora_delta_t 10 \
--adalora_orth_reg_weight 0.5 \
--lora_alpha 32 \
--lora_qkv_mlp_dense \
--use_4bit_quantization False \
--use_nested_quant True \
--bnb_4bit_compute_dtype "bfloat16" \
--use_flash_attn False
EOF

echo $cmd

srun -o ${EXP_DIR}/slurm-peft-%j-%n.out -e ${EXP_DIR}/slurm-peft-%j-%n.err --no-container-mount-home --container-image="$CONTAINER" $MOUNTS bash -c "${cmd}"
set +x
